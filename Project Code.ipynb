{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID2214/FID3214 Assignment 3 Group no. 12\n",
    "\n",
    "Project members:\n",
    "\n",
    "Aksel Uhr, auhr@kth.se \n",
    "Olivia HÃ¶ft, hoft@kth.se \n",
    "Ilias Merentitis, iliasme@kth.se\n",
    "\n",
    "Declaration\n",
    "\n",
    "By submitting this solution, it is hereby declared that all individuals listed above have contributed to the solution, either with code that appear in the final solution below, or with code that has been evaluated and compared to the final solution, but for some reason has been excluded. It is also declared that all project members fully understand all parts of the final solution and can explain it upon request.\n",
    "\n",
    "It is furthermore declared that the code below is a contribution by the project members only, and specifically that no part of the solution has been copied from any other source (except for lecture slides at the course ID2214/FID3214) and no part of the solution has been provided by someone not listed as project member above.\n",
    "It is furthermore declared that it has been understood that no other library/package than the Python 3 standard library, NumPy, pandas, time and sklearn.tree, may be used in the solution for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from rdkit import Chem\n",
    "import rdkit.Chem.rdMolDescriptors as d\n",
    "import rdkit.Chem.Descriptors as d2\n",
    "import rdkit.Chem.Fragments as f\n",
    "import rdkit.Chem.Lipinski as l\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import mean\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"training_smiles.csv\")\n",
    "test_df = pd.read_csv(\"test_smiles.csv\")\n",
    "seed = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection(train):\n",
    "    dfCopy2 = train.copy()\n",
    "    \n",
    "    dfCopy2=dfCopy2.drop(labels=['INDEX'], axis=1)\n",
    "    labels = dfCopy2[\"ACTIVE\"]\n",
    "    dfCopy2 = dfCopy2.drop(columns = [\"ACTIVE\"])\n",
    "    \n",
    "    dfCopy2['SMILES'] = dfCopy2['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    dfCopy2['NumAtoms'] = dfCopy2['SMILES'].apply(lambda x: x.GetNumAtoms())\n",
    "    dfCopy2['HeavyAtomCount']=dfCopy2['SMILES'].apply(lambda x: l.HeavyAtomCount(x))\n",
    "    dfCopy2['CalcExactMolWt']=dfCopy2['SMILES'].apply(lambda x: d.CalcExactMolWt(x))\n",
    "    dfCopy2['fr_Al_COO']=dfCopy2['SMILES'].apply(lambda x: f.fr_Al_COO(x))\n",
    "    dfCopy2['HsNumAtoms'] = dfCopy2[\"SMILES\"].apply(lambda x: Chem.AddHs(x).GetNumAtoms())\n",
    "    \n",
    "    morganFingerPrint=[np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)) for x in dfCopy2['SMILES']]\n",
    "    morganFingerPrint=pd.DataFrame(morganFingerPrint)\n",
    "    morganFingerPrint.columns=['fp_'+str(x) for x in morganFingerPrint.columns]    \n",
    "    dfCopy2 = pd.concat([dfCopy2, morganFingerPrint], axis=1, join='inner')\n",
    "    dfCopy2=dfCopy2.drop(labels=['SMILES'], axis=1)\n",
    "    \n",
    "    return dfCopy2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature_selection()\n",
    "df, y_res = feature_selection(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y_res, test_size=0.2, stratify=y_res) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make copies of the dataframes\n",
    "X_trainCopy = X_train.copy()\n",
    "y_trainCopy = y_train.copy()\n",
    "X_testCopy = X_test.copy()\n",
    "y_testCopy = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot Histograms of selected features\n",
    "withoutMorgan = X_trainCopy.iloc[:, :5]\n",
    "withoutMorgan.hist(figsize=(12,12), xrot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features\n",
    "corrs = withoutMorgan.corr()\n",
    "display(corrs)\n",
    "\n",
    "# Heatmap of correlations\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corrs, cmap='RdBu_r', annot=True)\n",
    "plt.show()\n",
    "\n",
    "#Delete the correlatedFeatures\n",
    "X_trainCopy = X_trainCopy.drop(columns = [\"HeavyAtomCount\", \"CalcExactMolWt\", \"HsNumAtoms\"])\n",
    "X_testCopy = X_testCopy.drop(columns = [\"HeavyAtomCount\", \"CalcExactMolWt\", \"HsNumAtoms\"])\n",
    "withoutMorgan = withoutMorgan.drop(columns = [\"HeavyAtomCount\", \"CalcExactMolWt\", \"HsNumAtoms\"])\n",
    "\n",
    "# Correlation between features\n",
    "corrs = withoutMorgan.corr()\n",
    "display(corrs)\n",
    "\n",
    "# Heatmap of correlations\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corrs, cmap='RdBu_r', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Num of NaN in train: \", X_trainCopy.isna().sum().sum())\n",
    "print(\"Training data shape: \", X_trainCopy.shape)\n",
    "print(\"testing data shape:  \", X_testCopy.shape)\n",
    "X_trainCopy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pre_processing(train):\n",
    "    imp = SimpleImputer(strategy=\"mean\")\n",
    "    imp.fit(train)\n",
    "    imputatedDf = imp.transform(train)\n",
    "    binning = KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\")\n",
    "    binning.fit(imputatedDf)\n",
    "    binnedDf = binning.transform(imputatedDf)\n",
    "    return binnedDf, imp, binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pre_processing(test, imputation, binning):\n",
    "    imputation.fit(test)\n",
    "    test = imputation.transform(test)\n",
    "    binning.fit(test)\n",
    "    test = binning.transform(test)\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to choose model\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pipelinegnb= make_pipeline(SimpleImputer(strategy='mean'), KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\"), gnb)\n",
    "scores_gnb = cross_val_score(pipelinegnb, X_trainCopy, y_trainCopy, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "pipelinerf= make_pipeline(SimpleImputer(strategy='mean'), KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\"), rf)\n",
    "scores_rf = cross_val_score(pipelinerf, X_trainCopy, y_trainCopy, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([scores_rf, scores_gnb])\n",
    "# NB\n",
    "print('Mean ROC AUC for GaussianNB: %.3f' % mean(scores_gnb))\n",
    "\n",
    "# Random forest\n",
    "print('Mean ROC AUC for RandomForestClassifier: %.3f' % mean(scores_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the choosen model\n",
    "\n",
    "X_trainCopy, imp_dict, bin_dict =  create_pre_processing(X_trainCopy)\n",
    "\n",
    "clf = BalancedRandomForestClassifier(random_state=seed)\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [3, 5, 7], \n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param, n_jobs = -1)\n",
    "\n",
    "CV_clf.fit(X_trainCopy, y_trainCopy)\n",
    "\n",
    "print(\"best param: \", CV_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model on the test set\n",
    "X_testCopy = apply_pre_processing(X_testCopy, imp_dict, bin_dict)\n",
    "\n",
    "y_pred_proba = CV_clf.predict_proba(X_testCopy)\n",
    "y_pred_proba = y_pred_proba[:, 1:]\n",
    "print(\"y_pred_proba: \", y_pred_proba)\n",
    "\n",
    "y_pred = CV_clf.predict(X_testCopy)\n",
    "print(\"yPred: \", y_pred)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"auc: \", auc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(fpr, tpr,label='AUC')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random')\n",
    "plt.title('AUC:{}'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part2, More features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection2(train):\n",
    "    dfCopy2 = train.copy()\n",
    "    \n",
    "    dfCopy2=dfCopy2.drop(labels=['INDEX'], axis=1)\n",
    "    labels = dfCopy2[\"ACTIVE\"]\n",
    "    dfCopy2 = dfCopy2.drop(columns = [\"ACTIVE\"])\n",
    "\n",
    "    dfCopy2['SMILES'] = dfCopy2['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    dfCopy2['fr_Al_COO']=dfCopy2['SMILES'].apply(lambda x: f.fr_Al_COO(x))\n",
    "    dfCopy2['NOCount']=dfCopy2['SMILES'].apply(lambda x: l.NOCount(x))\n",
    "    dfCopy2['NUM_H_ACCEPTORS']=dfCopy2['SMILES'].apply(lambda x: l.NumHAcceptors(x))\n",
    "    dfCopy2['NUM_H_DONORS']=dfCopy2['SMILES'].apply(lambda x: l.NumHDonors(x))\n",
    "    dfCopy2[\"NUM_OF_ATOMS\"] = dfCopy2['SMILES'].apply(lambda x: x.GetNumAtoms())\n",
    "    dfCopy2[\"DENSITY\"] = dfCopy2.apply(lambda x: (d2.FpDensityMorgan1(x[\"SMILES\"])), axis=1)    \n",
    "    dfCopy2[\"MAX_PCHARGE\"] = dfCopy2.apply(lambda x: (d2.MaxPartialCharge(x[\"SMILES\"])), axis=1) \n",
    "    dfCopy2[\"MIN_PCHARGE\"] = dfCopy2.apply(lambda x: (d2.MinPartialCharge(x[\"SMILES\"])), axis=1) \n",
    "    dfCopy2[\"MOLDESCRIPTOR\"] = dfCopy2.apply(lambda x: (d.CalcNumRings(x[\"SMILES\"])), axis=1)   \n",
    "\n",
    "    morganFingerPrint=[np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)) for x in dfCopy2['SMILES']]\n",
    "    morganFingerPrint=pd.DataFrame(morganFingerPrint)\n",
    "    morganFingerPrint.columns=['fp_'+str(x) for x in morganFingerPrint.columns]    \n",
    "    dfCopy2 = pd.concat([dfCopy2, morganFingerPrint], axis=1, join='inner')\n",
    "    dfCopy2=dfCopy2.drop(labels=['SMILES'], axis=1)\n",
    "    \n",
    "    return dfCopy2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y_res = feature_selection2(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y_res, test_size=0.2, stratify=y_res)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make copies of the dataframes\n",
    "X_trainCopy = X_train.copy()\n",
    "y_trainCopy = y_train.copy()\n",
    "X_testCopy = X_test.copy()\n",
    "y_testCopy = y_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Histograms of selected features\n",
    "withoutMorgan = X_trainCopy.iloc[:, :12]\n",
    "withoutMorgan.hist(figsize=(12,12), xrot=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features\n",
    "corrs = withoutMorgan.corr()\n",
    "display(corrs)\n",
    "\n",
    "# Heatmap of correlations\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corrs, cmap='RdBu_r', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num of NaN in train: \", X_trainCopy.isna().sum().sum())\n",
    "print(\"Training data shape: \", X_trainCopy.shape)\n",
    "print(\"testing data shape:  \", X_testCopy.shape)\n",
    "X_trainCopy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation to choose model\n",
    "\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "pipelinegnb= make_pipeline(SimpleImputer(strategy='mean'), KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\"), gnb)\n",
    "scores_gnb = cross_val_score(pipelinegnb, X_trainCopy, y_trainCopy, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "pipelinerf= make_pipeline(SimpleImputer(strategy='mean'), KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\"), rf)\n",
    "scores_rf = cross_val_score(pipelinerf, X_trainCopy, y_trainCopy, scoring='roc_auc', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([scores_rf, scores_gnb])\n",
    "# NB\n",
    "print('Mean ROC AUC for GaussianNB: %.3f' % mean(scores_gnb))\n",
    "\n",
    "# Random forest\n",
    "print('Mean ROC AUC for RandomForestClassifier: %.3f' % mean(scores_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the choosen model\n",
    "\n",
    "X_trainCopy, imp_dict, bin_dict=  create_pre_processing(X_trainCopy)\n",
    "\n",
    "clf = BalancedRandomForestClassifier(random_state=seed)\n",
    "\n",
    "param = {\n",
    "    'n_estimators': [10, 20, 30],\n",
    "    'max_features' : ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [3, 5, 7],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "\n",
    "CV_clf = GridSearchCV(estimator=clf, param_grid=param, n_jobs = -1, scoring = 'roc_auc')\n",
    "\n",
    "CV_clf.fit(X_trainCopy, y_trainCopy)\n",
    "\n",
    "print(\"best param: \", CV_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model on the test set\n",
    "X_testCopy = apply_pre_processing(X_testCopy, imp_dict, bin_dict)\n",
    "\n",
    "y_pred_proba = CV_clf.predict_proba(X_testCopy)\n",
    "y_pred_proba = y_pred_proba[:, 1:]\n",
    "print(\"y_pred_proba: \", y_pred_proba)\n",
    "\n",
    "y_pred = CV_clf.predict(X_testCopy)\n",
    "print(\"yPred: \", y_pred)\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "print(\"auc: \", auc)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(fpr, tpr,label='AUC')\n",
    "plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random')\n",
    "plt.title('AUC:{}'.format(auc))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE PREDICTION ON TEST FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection3(test):\n",
    "    dfCopy2 = test.copy()\n",
    "    \n",
    "    dfCopy2=dfCopy2.drop(labels=['INDEX'], axis=1)\n",
    "\n",
    "    dfCopy2['SMILES'] = dfCopy2['SMILES'].apply(lambda x: Chem.MolFromSmiles(x))\n",
    "    dfCopy2['fr_Al_COO']=dfCopy2['SMILES'].apply(lambda x: f.fr_Al_COO(x))\n",
    "    dfCopy2['NOCount']=dfCopy2['SMILES'].apply(lambda x: l.NOCount(x))\n",
    "    dfCopy2['NUM_H_ACCEPTORS']=dfCopy2['SMILES'].apply(lambda x: l.NumHAcceptors(x))\n",
    "    dfCopy2['NUM_H_DONORS']=dfCopy2['SMILES'].apply(lambda x: l.NumHDonors(x))\n",
    "    dfCopy2[\"NUM_OF_ATOMS\"] = dfCopy2['SMILES'].apply(lambda x: x.GetNumAtoms())\n",
    "    dfCopy2[\"DENSITY\"] = dfCopy2.apply(lambda x: (d2.FpDensityMorgan1(x[\"SMILES\"])), axis=1)    \n",
    "    dfCopy2[\"MAX_PCHARGE\"] = dfCopy2.apply(lambda x: (d2.MaxPartialCharge(x[\"SMILES\"])), axis=1) \n",
    "    dfCopy2[\"MIN_PCHARGE\"] = dfCopy2.apply(lambda x: (d2.MinPartialCharge(x[\"SMILES\"])), axis=1) \n",
    "    dfCopy2[\"MOLDESCRIPTOR\"] = dfCopy2.apply(lambda x: (d.CalcNumRings(x[\"SMILES\"])), axis=1)  \n",
    "\n",
    "    morganFingerPrint=[np.array(AllChem.GetMorganFingerprintAsBitVect(x,2,nBits=124)) for x in dfCopy2['SMILES']]\n",
    "    morganFingerPrint=pd.DataFrame(morganFingerPrint)\n",
    "    morganFingerPrint.columns=['fp_'+str(x) for x in morganFingerPrint.columns]    \n",
    "    dfCopy2 = pd.concat([dfCopy2, morganFingerPrint], axis=1, join='inner')\n",
    "    dfCopy2=dfCopy2.drop(labels=['SMILES'], axis=1)\n",
    "    \n",
    "    return dfCopy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on the original test file.\n",
    "\n",
    "test_df_copy = test_df.copy()\n",
    "test_df_copy = feature_selection3(test_df_copy)\n",
    "\n",
    "test_df_copy = apply_pre_processing(test_df_copy, imp_dict, bin_dict)\n",
    "\n",
    "y_pred_proba_test = CV_clf.predict_proba(test_df_copy)\n",
    "y_pred_proba_test = y_pred_proba_test[:, 1:]\n",
    "print(\"y_pred_proba: \", y_pred_proba_test)\n",
    "\n",
    "y_pred_test = CV_clf.predict(test_df_copy)\n",
    "print(\"yPred: \", y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('12.txt', 'w')\n",
    "np.savetxt(f, y_pred_proba_test, newline='\\n')\n",
    "f.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
